# -*- coding: utf-8 -*-
"""fraud_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yOL19PHrtfNaz9jDSa_Ln7JgAp5Dmo8o

# Import Dataset
"""

! pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d mlg-ulb/creditcardfraud

! mkdir dataset

! unzip creditcardfraud.zip -d dataset

"""# Data Preprocessing"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('dataset/creditcard.csv')
data.head()

data.isna().any()

data.Class.value_counts()

data.corrwith(data.Class).plot.bar(
        figsize = (20, 10), title = "Correlation with class", fontsize = 15,
        rot = 45, grid = True)
plt.show()

data.corrwith(data.Class, axis=0)

data.columns

data = data.drop(['Time'], axis=1)
data.head(2)

X = data.iloc[:,:-1].values
X[:3]

y = data.iloc[:,-1].values
y[:4]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 40, test_size = 0.2)
X_train

sns.distplot(X_train[:,-1])

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler_fit = scaler.fit(X_train[:,-1].reshape(-1,1))
normalisedAmount = scaler_fit.transform(X_train[:,-1].reshape(-1,1))
normalisedAmount

import pickle
pickle_out = open("scaler.pickle","wb")
pickle.dump(scaler_fit, pickle_out)
pickle_out.close()

X_train[:,-1] = normalisedAmount.reshape(1,-1)
X_train[:,-1]

"""# Decision Trees"""

from sklearn.tree import DecisionTreeClassifier
classifier_decision_tree = DecisionTreeClassifier(random_state = 0,
                                    criterion = 'gini',  splitter='best', min_samples_leaf=1, min_samples_split=2)
classifier_decision_tree.fit(X_train, y_train)

y_pred = classifier_decision_tree.predict(X_test)
y_pred

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

results = pd.DataFrame([['Decision tree', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
classifier_random_forest = RandomForestClassifier(random_state = 0, n_estimators = 100,
                                    criterion = 'entropy')
classifier_random_forest.fit(X_train, y_train)

y_pred = classifier_random_forest.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
import random
verbosity = random.randint(1,100)
classifier_logistic_regression = clf = LogisticRegression(random_state=0, max_iter=200, verbose=verbosity)
classifier_logistic_regression.fit(X_train, y_train)

y_pred = classifier_logistic_regression.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

"""# Support Vector Machine"""

from sklearn.svm import SVC
random_state = random.randint(1,100)
classifier_svc = SVC(kernel='rbf', degree=5, random_state=random_state)
classifier_svc.fit(X_train, y_train)

y_pred = classifier_svc.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Support Vector Machine', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

"""# Neural Network Multi-Layer Perceptron using Sklearn"""

from sklearn.neural_network import MLPClassifier
random_state = random.randint(1,100)
classifier_mtp = MLPClassifier(n_iter_no_change = 50, max_iter = 300, random_state=random_state)
classifier_mtp.fit(X_train, y_train)

y_pred = classifier_mtp.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Multi Layer Perceptron', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

"""# Neural Network Multi-Layer Perceptron using Keras and Tensorflow"""

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

tf.debugging.set_log_device_placement(True)

import keras
from keras.models import Sequential
from keras.layers import Dense

classifier_ann = Sequential()
classifier_ann.add(Dense(units =30 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 29))
classifier_ann.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu'))
classifier_ann.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))
classifier_ann.add(Dense(units = 5, kernel_initializer = 'uniform', activation = 'relu'))
classifier_ann.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))
classifier_ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
classifier_ann.fit(X_train, y_train, batch_size = 32, epochs = 100)

y_pred = classifier_ann.predict(X_test)
y_pred

y_pred = (y_pred > 0.5)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Neural Network using Tensorflow and Keras', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

"""# Final Pipeline"""

x1_train = classifier_decision_tree.predict(X_train)
x2_train = classifier_random_forest.predict(X_train)
x3_train = classifier_logistic_regression.predict(X_train)
x4_train = classifier_svc.predict(X_train)
x5_train = classifier_mtp.predict(X_train)
x6_train = classifier_ann.predict(X_train).astype(int).reshape(1,-1)[0]
data = {
    'DecisionTree' : x1_train,
    'RandomForest' : x2_train,
    'LogisticRegression' : x3_train,
    'SupportVectorMachine' : x4_train,
    'MTPSklearn' : x5_train,
    'ANN' : x6_train,
    'Output': y_train,
}
pipeline_train = pd.DataFrame(data)
pipeline_train.head()

x1_test = classifier_decision_tree.predict(X_test)
x2_test = classifier_random_forest.predict(X_test)
x3_test = classifier_logistic_regression.predict(X_test)
x4_test = classifier_svc.predict(X_test)
x5_test = classifier_mtp.predict(X_test)
x6_test = classifier_ann.predict(X_test).astype(int).reshape(1,-1)[0]
data = {
    'DecisionTree' : x1_test,
    'RandomForest' : x2_test,
    'LogisticRegression' : x3_test,
    'SupportVectorMachine' : x4_test,
    'MTPSklearn' : x5_test,
    'ANN' : x6_test,
    'Output': y_test,
}
pipeline_test = pd.DataFrame(data)
pipeline_test.head()

pipeline_data = pd.concat([pipeline_train, pipeline_test])
pipeline_data.head()

X = pipeline_data.iloc[:,:-1].values
X[:3]

y = pipeline_data.iloc[:,-1].values
y[:4]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 40, test_size = 0.2)
X_train[:1]

pipeline_classifier = RandomForestClassifier(random_state = 0, n_estimators = 100,
                                    criterion = 'entropy')
pipeline_classifier.fit(X_train, y_train)

y_pred = pipeline_classifier.predict(X_test)
y_pred

acc = accuracy_score(y_test, y_pred)
acc

prec = precision_score(y_test, y_pred)
prec

rec = recall_score(y_test, y_pred)
rec

f1 = f1_score(y_test, y_pred)
f1

model_results = pd.DataFrame([['Final Pipeline', acc, prec, rec, f1]],
               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])
results = results.append(model_results, ignore_index = True)
results

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))
plt.figure(figsize = (10,7))
sns.set(font_scale=1.4)
sns.heatmap(df_cm, annot=True, fmt='g')
print("Test Data Accuracy: %0.4f" % accuracy_score(y_test, y_pred))

"""# Save classifiers"""

import pickle
classifiers = [classifier_decision_tree, classifier_random_forest, 
               classifier_logistic_regression, classifier_svc, 
               classifier_mtp, pipeline_classifier]
filenames = ['decision_tree.sav', 'random_forest.sav',
            'logistic_regression.sav', 'svc.sav',
            'mtp.sav', 'pipeline.sav']
for classifier, filename in zip(classifiers, filenames):
  pickle.dump(classifier, open(filename, 'wb'))

model_json = classifier_ann.to_json()
with open("ann.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
classifier_ann.save_weights("model.h5")
print("Saved model to disk")

!pwd

"""# GPU Speedup"""

import tensorflow as tf
import timeit

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  print(
      '\n\nThis error most likely means that this notebook is not '
      'configured to use a GPU.  Change this in Notebook Settings via the '
      'command palette (cmd/ctrl-shift-P) or the Edit menu.\n\n')
  raise SystemError('GPU device not found')

def cpu():
  with tf.device('/cpu:0'):
    random_image_cpu = tf.random.normal((100, 100, 100, 3))
    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)
    return tf.math.reduce_sum(net_cpu)

def gpu():
  with tf.device('/device:GPU:0'):
    random_image_gpu = tf.random.normal((100, 100, 100, 3))
    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)
    return tf.math.reduce_sum(net_gpu)
  
cpu()
gpu()

# Run the op several times.
print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '
      '(batch x height x width x channel). Sum of ten runs.')
print('CPU (s):')
cpu_time = timeit.timeit('cpu()', number=10, setup="from __main__ import cpu")
print(cpu_time)
print('GPU (s):')
gpu_time = timeit.timeit('gpu()', number=10, setup="from __main__ import gpu")
print(gpu_time)
print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))